# Wrangle and Analyze Data
Using Python and its libraries, I gathered data from a variety of sources and in a variety of formats, assessed its quality and tidiness, cleaned it, then performed data analysis and created informative visualizations.


## Project Files

- [wrangle_act.ipynb](https://github.com/RawanAlsaedi/Wrangle-and-Analyze-Data/blob/main/wrangle_act_project_udacity.ipynb):
Contain code for gathering, assessing, cleaning, analyzing, and visualizing data.

- [wrangle_report.pdf](https://github.com/RawanAlsaedi/Wrangle-and-Analyze-Data/blob/main/wrangle_report.pdf):
Documentation for data wrangling steps: gather, assess, and clean.

- [act_report.pdf](https://github.com/RawanAlsaedi/Wrangle-and-Analyze-Data/blob/main/act_report.pdf):
Documentation of analysis and insights into final data.

- [twitter_archive_enhanced.csv](https://github.com/RawanAlsaedi/Wrangle-and-Analyze-Data/blob/main/twitter-archive-enhanced%20(12).csv):
The dataset contain the tweet archive of Twitter user @dog_rates .

- [image_predictions.tsv](https://github.com/RawanAlsaedi/Wrangle-and-Analyze-Data/blob/main/image-predictions.tsv):
The tweet image predictions, i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. 

- [tweet_json.txt](https://github.com/RawanAlsaedi/Wrangle-and-Analyze-Data/blob/main/tweet-json2.txt):
File constructed via API.

- [twitter-api.py.txt](https://github.com/RawanAlsaedi/Wrangle-and-Analyze-Data/blob/main/twitter-api.py.txt):
To download tweets with API.

- [twitter_archive_master.csv](https://github.com/RawanAlsaedi/Wrangle-and-Analyze-Data/blob/main/twitter_archive_master.csv):
 Contain the combined and cleaned data.



## Key Libraries

```
import pandas as pd
import numpy as np
import requests
import tweepy
import json
import matplotlib.pyplot as plt
```

## Notes

- This project was developed using **_Jupyter_ _Notebook_**
